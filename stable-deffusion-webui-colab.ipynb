{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfKvWAVnz8OB"
      },
      "source": [
        "https://github.com/AUTOMATIC1111/stable-diffusion-webui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbSBMNZnmPt2"
      },
      "source": [
        "**Thanks for original colab to daswer123**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSP9suJcjlWs"
      },
      "outputs": [],
      "source": [
        "#Update python to 3.9\n",
        "!wget -O mini.sh https://repo.anaconda.com/miniconda/Miniconda3-py38_4.8.2-Linux-x86_64.sh\n",
        "!chmod +x mini.sh\n",
        "!bash ./mini.sh -b -f -p /usr/local\n",
        "!conda install -q -y jupyter\n",
        "!conda install -q -y google-colab -c conda-forge\n",
        "!python -m ipykernel install --name \"py39\" --user\n",
        "\n",
        "%cd /content/\n",
        "#@title #Simple start webui stable diffusion by ataraxiadev.\n",
        "\n",
        "#@markdown Full loading of all components takes about 7-8 minutes\n",
        "\n",
        "#@markdown ##Dowload model:\n",
        "Model = \"Stable-diffusion 1.5\" #@param [\"Stable-diffusion 1.4\",\"Stable-diffusion 1.5\",\"waifu-diffusion 1.2\", \"waifu-diffusion 1.3 release\"]\n",
        "\n",
        "#@markdown ##Gdrive:\n",
        "#@markdown #####Mount gdrive models folder\n",
        "mount_models_gdrive = True #@param{type:\"boolean\"}\n",
        "#@markdown #####Write the path to the models folder\n",
        "gdrive_models_path = \"stable-diffusion/models/\" #@param {type:\"string\"}\n",
        "#@markdown #####Copy models from gdrive to colab?\n",
        "copy_models_gdrive = True #@param{type:\"boolean\"}\n",
        "#@markdown #####Mount gdrive hypernetworks folder\n",
        "mount_hypernetworks_gdrive = True #@param{type:\"boolean\"}\n",
        "#@markdown #####Write the path to the hypernetworks folder\n",
        "gdrive_hypernetworks_path = \"stable-diffusion/hypernetworks/\" #@param {type:\"string\"}\n",
        "#@markdown #####Mount gdrive config folder\n",
        "mount_config_gdrive = True #@param{type:\"boolean\"}\n",
        "#@markdown #####Write the path to the config folder\n",
        "gdrive_config_path = \"stable-diffusion/config/\" #@param {type:\"string\"}\n",
        "#@markdown #####Mount gdrive embeddings folder\n",
        "mount_embeddings_gdrive = True #@param{type:\"boolean\"}\n",
        "#@markdown #####Write the path to the embeddings folder\n",
        "gdrive_embeddings_path = \"stable-diffusion/embeddings/\" #@param {type:\"string\"}\n",
        "#@markdown #####Mount gdrive cache folder\n",
        "mount_cache_gdrive = True #@param{type:\"boolean\"}\n",
        "#@markdown #####Write the path to the transformers cache folder\n",
        "gdrive_cache_path = \"stable-diffusion/transformers-cache/\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown #####Path to custom vae on your gdrive (optionally)\n",
        "custom_vae_name = \"vae-ft-mse.vae.pt\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ##Extra\n",
        "#@markdown xformers increases the generation speed by 1.5 - 3 times, on T4 the generation speed increases by 1.5 times \n",
        "install_xformers = True #@param{type:\"boolean\"}\n",
        "download_hypernetworks_modules = True #@param{type:\"boolean\"}\n",
        "#@markdown Make result same as nai , after loading in setting, setup: **clip skip: 2 , delta noise: 31337**\n",
        "special_config_for_nai = True #@param{type:\"boolean\"}\n",
        "#@markdown ##### If you do not want to load the model from google disk, but want to connect it for example to display pictures, then select this checkbox\n",
        "mount_gdrive_for_outputs = True #@param{type:\"boolean\"}\n",
        "#@markdown #####There is a bug in which the output of the image can cause lag and they will not be displayed, for this instead of running gradio uses localltunel, which allows to fix this bug\n",
        "Use_localtunnel = True #@param{type:\"boolean\"}\n",
        "#@markdown #####Do you want to use dark theme?:\n",
        "use_darktheme = True #@param{type:\"boolean\"}\n",
        "\n",
        "#@markdown #####You can set additional parameters:\n",
        "additional_params = \"\" #@param{type:\"string\"}\n",
        "\n",
        "import time\n",
        "\n",
        "if mount_models_gdrive == True or mount_gdrive_for_outputs == True \\\n",
        "  or mount_hypernetworks_gdrive == True or mount_config_gdrive == True \\\n",
        "  or mount_outputs_gdrive == True or mount_cache_gdrive == True:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "!nvidia-smi\n",
        "!ls /usr/share/fonts/truetype/\n",
        "!npm install -g localtunnel\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow_io\n",
        "!pip install gdown\n",
        "# !pip install git+https://github.com/KichangKim/DeepDanbooru.git@edf73df4cdaeea2cf00e9ac08bd8a9026b7a7b26\n",
        "!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "%cd /content/stable-diffusion-webui\n",
        "\n",
        "if mount_models_gdrive == False:\n",
        "  if(Model == \"Stable-diffusion 1.4\"):\n",
        "    user_header = f\"\\\"Authorization: Bearer {'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'}\\\"\"\n",
        "    !wget --header={user_header} https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt -O model.ckpt\n",
        "  elif(Model == \"Stable-diffusion 1.5\"):\n",
        "    user_header = f\"\\\"Authorization: Bearer {'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'}\\\"\"\n",
        "    !wget --header={user_header} https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt -O /content/stable-diffusion-webui/models/Stable-diffusion/sd-v1-5.ckpt\n",
        "  elif(Model == \"waifu-diffusion 1.2\"):\n",
        "    !wget \"http://wd.links.sd:8880/wd-v1-2-full-ema.ckpt\" -O /content/stable-diffusion-webui/model.ckpt\n",
        "  elif(Model == \"waifu-diffusion 1.3 release\"):\n",
        "    !gdown https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float32.ckpt -O /content/stable-diffusion-webui/model.ckpt\n",
        "  else:\n",
        "    !gdown https://drive.google.com/uc?id=1EdZmlteF8EThBu9Rpf2JMRFSLbVD7EXa -O /content/stable-diffusion-webui/model.ckpt\n",
        "\n",
        "if (download_hypernetworks_modules == True) and mount_hypernetworks_gdrive == False:\n",
        "  %cd /content/stable-diffusion-webui/models/\n",
        "  !gdown https://huggingface.co/Daswer123/asdasdadsa/resolve/main/hypernetworks.zip -O /content/stable-diffusion-webui/models/hypernetworks.zip \n",
        "  !unzip /content/stable-diffusion-webui/models/hypernetworks.zip\n",
        "  !rm -f /content/stable-diffusion-webui/models/hypernetworks.zip\n",
        "\n",
        "#Instal xformers\n",
        "if (install_xformers):\n",
        "  %cd /content/stable-diffusion-webui/\n",
        "  !mkdir repositories\n",
        "  %cd /content/stable-diffusion-webui/repositories\n",
        "  !git clone https://github.com/openai/triton.git\n",
        "  %cd triton/python\n",
        "  !pip install -e .\n",
        "  \n",
        "  from IPython.display import clear_output\n",
        "  import time\n",
        "  from IPython.display import HTML\n",
        "  from subprocess import getoutput\n",
        "  import os\n",
        "  s = getoutput('nvidia-smi')\n",
        "  if 'T4' in s:\n",
        "    gpu = 'T4'\n",
        "  elif 'P100' in s:\n",
        "    gpu = 'P100'\n",
        "  elif 'V100' in s:\n",
        "    gpu = 'V100'\n",
        "  elif 'A100' in s:\n",
        "    gpu = 'A100'\n",
        "  \n",
        "  if (gpu=='T4'):\n",
        "    %pip install -q https://github.com/daswer123/xformers_prebuild_wheels/raw/main/Google%20Collab/T4/python38/xformers-0.0.14.dev0-cp38-cp38-linux_x86_64.whl\n",
        "    \n",
        "  elif (gpu=='P100'):\n",
        "    %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "  \n",
        "  elif (gpu=='V100'):\n",
        "    %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "  \n",
        "  elif (gpu=='A100'):\n",
        "    %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "if(special_config_for_nai == True):\n",
        "   %cd /content\n",
        "   !git clone https://github.com/DominikDoom/a1111-sd-webui-tagcomplete temp\n",
        "   !cp -r temp/javascript /content/stable-diffusion-webui/\n",
        "   !cp -r temp/tags /content/stable-diffusion-webui/\n",
        "   !cp -r temp/scripts /content/stable-diffusion-webui/\n",
        "   !rm -rf temp\n",
        "\n",
        "\n",
        "time.sleep(1)\n",
        "%cd /content/stable-diffusion-webui\n",
        "\n",
        "dirs_cmdline_options = \"\"\n",
        "\n",
        "if mount_models_gdrive == True:\n",
        "  models_path = \"/content/drive/MyDrive/\" + gdrive_models_path\n",
        "  if copy_models_gdrive == True:\n",
        "    !cp -aT $models_path/* /content/models\n",
        "    dirs_cmdline_options += f\"--ckpt-dir={/content/models} \"\n",
        "  else:\n",
        "    dirs_cmdline_options += f\"--ckpt-dir={models_path} \"\n",
        "  !cp $models_path/v2.pt /content/stable-diffusion-webui\n",
        "  !cp $models_path/v2enable.py /content/stable-diffusion-webui/scripts\n",
        "if mount_hypernetworks_gdrive == True:\n",
        "  hypernetworks_path = \"/content/drive/MyDrive/\" + gdrive_hypernetworks_path\n",
        "  dirs_cmdline_options += f\"--hypernetwork-dir={hypernetworks_path} \"\n",
        "if mount_config_gdrive == True:\n",
        "  config_path = \"/content/drive/MyDrive/\" + gdrive_config_path\n",
        "  dirs_cmdline_options += f\"--styles-file={config_path}styles.csv --ui-settings-file={config_path}config.json --ui-config-file={config_path}ui-config.json \"\n",
        "if mount_embeddings_gdrive == True:\n",
        "  embeddings_path = \"/content/drive/MyDrive/\" + gdrive_embeddings_path\n",
        "  dirs_cmdline_options += f\"--embeddings-dir={embeddings_path} \"\n",
        "if mount_cache_gdrive == True:\n",
        "  cache_dir = \"/content/drive/MyDrive/\" + gdrive_cache_path\n",
        "  %env TRANSFORMERS_CACHE=$cache_dir\n",
        "if custom_vae_name != \"\" and mount_models_gdrive == True:\n",
        "  if copy_models_gdrive == True:\n",
        "    vae_path = \"/content/models\" + \n",
        "  else:\n",
        "    vae_path = \"/content/drive/MyDrive/\" + gdrive_models_path + \"/\" + custom_vae_name\n",
        "  dirs_cmdline_options += f\"--vae-path={vae_path} \"\n",
        "if use_darktheme == True:\n",
        "  dirs_cmdline_options += f\"--theme dark \"\n",
        "\n",
        "if Use_localtunnel == True:\n",
        "  !nohup lt -p 7860 > lt.log 2>&1 &  \n",
        "  time.sleep(2)\n",
        "  with open('/content/stable-diffusion-webui/lt.log', 'r') as testwritefile:\n",
        "    print(\"\\033[92m\" + \"Wait for the model to load and follow this link\")\n",
        "    print(testwritefile.read())\n",
        "    print(\"\\033[95m\")  \n",
        "  !python launch.py --deepdanbooru --xformers --lowram $dirs_cmdline_options $additional_params\n",
        "else:\n",
        "  !python launch.py --deepdanbooru --share --xformers --lowram $dirs_cmdline_options $additional_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLt0o9_XMEgs"
      },
      "source": [
        "#If something get wrong\n",
        "So that you don't have to restart the colab, you can quickly do it here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPXSMTXPMOkq"
      },
      "outputs": [],
      "source": [
        "#@title #Simple Restarting\n",
        "#@markdown ###Do you want to use/leave the localtunnel?:\n",
        "Use_Localtunnel = True #@param{type:\"boolean\"}\n",
        "\n",
        "#@markdown ###Do you want to use dark theme?:\n",
        "use_darktheme = True #@param{type:\"boolean\"}\n",
        "\n",
        "#@markdown #####You can set additional parameters:\n",
        "additional_params = \"\" #@param{type:\"string\"}\n",
        "\n",
        "#@markdown ##Gdrive:\n",
        "#@markdown #####Mount gdrive models folder\n",
        "mount_models_gdrive = True #@param{type:\"boolean\"}\n",
        "#@markdown #####Write the path to the models folder\n",
        "gdrive_models_path = \"stable-diffusion/models/\" #@param {type:\"string\"}\n",
        "#@markdown #####Copy models from gdrive to colab?\n",
        "copy_models_gdrive = True #@param{type:\"boolean\"}\n",
        "#@markdown #####Mount gdrive hypernetworks folder\n",
        "mount_hypernetworks_gdrive = True #@param{type:\"boolean\"}\n",
        "#@markdown #####Write the path to the hypernetworks folder\n",
        "gdrive_hypernetworks_path = \"stable-diffusion/hypernetworks/\" #@param {type:\"string\"}\n",
        "#@markdown #####Mount gdrive config folder\n",
        "mount_config_gdrive = True #@param{type:\"boolean\"}\n",
        "#@markdown #####Write the path to the config folder\n",
        "gdrive_config_path = \"stable-diffusion/config/\" #@param {type:\"string\"}\n",
        "#@markdown #####Mount gdrive embeddings folder\n",
        "mount_embeddings_gdrive = True #@param{type:\"boolean\"}\n",
        "#@markdown #####Write the path to the embeddings folder\n",
        "gdrive_embeddings_path = \"stable-diffusion/embeddings/\" #@param {type:\"string\"}\n",
        "#@markdown #####Mount gdrive cache folder\n",
        "mount_cache_gdrive = True #@param{type:\"boolean\"}\n",
        "#@markdown #####Write the path to the transformers cache folder\n",
        "gdrive_cache_path = \"stable-diffusion/transformers-cache/\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown #####Path to custom vae on your gdrive (optionally)\n",
        "custom_vae_name = \"vae-ft-mse.vae.pt\" #@param {type:\"string\"}\n",
        "\n",
        "dirs_cmdline_options = \"\"\n",
        "\n",
        "if mount_models_gdrive == True:\n",
        "  models_path = \"/content/drive/MyDrive/\" + gdrive_models_path\n",
        "  if copy_models_gdrive == True:\n",
        "    !cp -aT $models_path/* /content/models\n",
        "    dirs_cmdline_options += f\"--ckpt-dir={/content/models} \"\n",
        "  else:\n",
        "    dirs_cmdline_options += f\"--ckpt-dir={models_path} \"\n",
        "  !cp $models_path/v2.pt /content/stable-diffusion-webui\n",
        "  !cp $models_path/v2enable.py /content/stable-diffusion-webui/scripts\n",
        "if mount_hypernetworks_gdrive == True:\n",
        "  hypernetworks_path = \"/content/drive/MyDrive/\" + gdrive_hypernetworks_path\n",
        "  dirs_cmdline_options += f\"--hypernetwork-dir={hypernetworks_path} \"\n",
        "if mount_config_gdrive == True:\n",
        "  config_path = \"/content/drive/MyDrive/\" + gdrive_config_path\n",
        "  dirs_cmdline_options += f\"--styles-file={config_path}/styles.csv --ui-settings-file={config_path}/config.json --ui-config-file={config_path}/ui-config.json \"\n",
        "if mount_embeddings_gdrive == True:\n",
        "  embeddings_path = \"/content/drive/MyDrive/\" + gdrive_embeddings_path\n",
        "  dirs_cmdline_options += f\"--embeddings-dir={embeddings_path} \"\n",
        "if mount_cache_gdrive == True:\n",
        "  cache_dir = \"/content/drive/MyDrive/\" + gdrive_cache_path\n",
        "  %env TRANSFORMERS_CACHE=$cache_dir\n",
        "if custom_vae_name != \"\" and mount_models_gdrive == True:\n",
        "  if copy_models_gdrive == True:\n",
        "    vae_path = \"/content/models\" + \n",
        "  else:\n",
        "    vae_path = \"/content/drive/MyDrive/\" + gdrive_models_path + \"/\" + custom_vae_name\n",
        "  dirs_cmdline_options += f\"--vae-path={vae_path} \"\n",
        "if use_darktheme == True:\n",
        "  dirs_cmdline_options += f\"--theme dark \"\n",
        "\n",
        "%cd /content/stable-diffusion-webui\n",
        "if Use_Localtunnel == True:\n",
        "  !nohup lt -p 7860 > lt.log 2>&1 &  \n",
        "  time.sleep(2)\n",
        "  with open('/content/stable-diffusion-webui/lt.log', 'r') as testwritefile:\n",
        "    print(\"\\033[92m\" + \"Wait for the model to load and follow this link\")\n",
        "    print(testwritefile.read())\n",
        "    print(\"\\033[95m\")\n",
        "  !python launch.py --deepdanbooru --xformers --lowram $dirs_cmdline_options $additional_params\n",
        "else:\n",
        "  !python launch.py --deepdanbooru --share --xformers --lowram $dirs_cmdline_options $additional_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_DDrz434rjP"
      },
      "source": [
        "# Extra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PJAL-jsgBslN"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Upload another model:\n",
        "Model = \"Stable-diffusion 1.5\" #@param [\"Stable-diffusion 1.4\",\"Stable-diffusion 1.5\",\"waifu-diffusion 1.2\", \"waifu-diffusion 1.3 release\"]\n",
        "\n",
        "if(Model == \"Stable-diffusion 1.4\"):\n",
        "    user_header = f\"\\\"Authorization: Bearer {'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'}\\\"\"\n",
        "    !wget --header={user_header} https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt -O /content/stable-diffusion-webui/models/Stable-diffusion/sd-v1-4.ckpt\n",
        "elif(Model == \"Stable-diffusion 1.5\"):\n",
        "    user_header = f\"\\\"Authorization: Bearer {'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'}\\\"\"\n",
        "    !wget --header={user_header} https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt -O /content/stable-diffusion-webui/models/Stable-diffusion/sd-v1-5.ckpt\n",
        "elif(Model == \"waifu-diffusion 1.2\"):\n",
        "    !wget \"http://wd.links.sd:8880/wd-v1-2-full-ema.ckpt\" -O /content/stable-diffusion-webui/models/Stable-diffusion/wd-v1-2.ckpt\n",
        "elif(Model == \"waifu-diffusion 1.3 release\"):\n",
        "    !gdown https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float32.ckpt -O /content/stable-diffusion-webui/models/Stable-diffusion/wd-v1-3.ckpt\n",
        "else:\n",
        "    !gdown https://drive.google.com/uc?id=1EdZmlteF8EThBu9Rpf2JMRFSLbVD7EXa -O /content/stable-diffusion-webui/model.ckpt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "go9QlQ0X4xf5"
      },
      "outputs": [],
      "source": [
        "#@markdown ###If you did not install xformers right away, you can do it here\n",
        "%cd /content/stable-diffusion-webui/\n",
        "!mkdir repositories\n",
        "%cd /content/stable-diffusion-webui/repositories\n",
        "!git clone https://github.com/openai/triton.git\n",
        "%cd triton/python\n",
        "!pip install -e .\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "from IPython.display import HTML\n",
        "from subprocess import getoutput\n",
        "import os\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "elif 'V100' in s:\n",
        "  gpu = 'V100'\n",
        "elif 'A100' in s:\n",
        "  gpu = 'A100'\n",
        "\n",
        "if (gpu=='T4'):\n",
        "  %pip install -q https://github.com/daswer123/xformers_prebuild_wheels/raw/main/Google%20Collab/T4/python38/xformers-0.0.14.dev0-cp38-cp38-linux_x86_64.whl\n",
        "  \n",
        "elif (gpu=='P100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='V100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='A100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "install_xformers = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "APmvyJgRtrHS"
      },
      "outputs": [],
      "source": [
        "#@markdown ###If you did not install hypernetwork modules right away, you can do it here\n",
        "\n",
        "%cd /content/stable-diffusion-webui/models/\n",
        "!gdown https://huggingface.co/Daswer123/asdasdadsa/resolve/main/hypernetworks.zip -O /content/stable-diffusion-webui/models/hypernetworks.zip \n",
        "!unzip /content/stable-diffusion-webui/models/hypernetworks.zip\n",
        "!rm -rf /content/stable-diffusion-webui/models/hypernetworks.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EWpqk2dmuB74"
      },
      "outputs": [],
      "source": [
        "#@markdown ###Special config for NAI model\n",
        "%cd /content\n",
        "!git clone https://github.com/DominikDoom/a1111-sd-webui-tagcomplete temp\n",
        "!cp -r temp/javascript /content/stable-diffusion-webui/\n",
        "!cp -r temp/tags /content/stable-diffusion-webui/\n",
        "!cp -r temp/scripts /content/stable-diffusion-webui/\n",
        "!rm -rf temp\n",
        "\n",
        "!wget https://gist.githubusercontent.com/AlukardBF/27c27f7982b2cdaafa3badd082d061c5/raw/eb95d63caaa1a7c108f8d5d0ed6913f47506a1d5/ui-config.js -O /content/stable-diffusion-webui/ui-config.json\n",
        "!wget https://gist.githubusercontent.com/AlukardBF/66d6450047dfa8e1f53b7586152497ff/raw/fff349d5469109acbaabdc9ee93657a2aea94222/config.json -O /content/stable-diffusion-webui/config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "J-onacINBGp0"
      },
      "outputs": [],
      "source": [
        "#@markdown ###Connect gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "h_DDrz434rjP"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
